{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(cwd + \"/preprocessing_data.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANGER</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISGUST</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAPPINESS</th>\n",
       "      <td>2128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>2038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SADNESS</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURPRISE</th>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image\n",
       "emotion         \n",
       "ANGER         67\n",
       "DISGUST        4\n",
       "HAPPINESS   2128\n",
       "NEUTRAL     2038\n",
       "SADNESS       36\n",
       "SURPRISE      80"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(train, columns=[\"image\", \"emotion\"])\n",
    "train.to_csv(\"train.csv\")\n",
    "\n",
    "train.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANGER</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISGUST</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HAPPINESS</th>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NEUTRAL</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SADNESS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURPRISE</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image\n",
       "emotion         \n",
       "ANGER         12\n",
       "DISGUST        2\n",
       "HAPPINESS    251\n",
       "NEUTRAL      211\n",
       "SADNESS        1\n",
       "SURPRISE       7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(test, columns=[\"image\", \"emotion\"])\n",
    "test.to_csv(\"test.csv\")\n",
    "\n",
    "test.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\TU\\2564_2\\CN240\\FacialExpressionRecognition\\feature_engineering.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/TU/2564_2/CN240/FacialExpressionRecognition/feature_engineering.ipynb#ch0000003?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mdlib\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39mimutils\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TU/2564_2/CN240/FacialExpressionRecognition/feature_engineering.ipynb#ch0000003?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimutils\u001b[39;00m \u001b[39mimport\u001b[39;00m face_utils\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/TU/2564_2/CN240/FacialExpressionRecognition/feature_engineering.ipynb#ch0000003?line=3'>4</a>\u001b[0m detector \u001b[39m=\u001b[39m dlib\u001b[39m.\u001b[39mget_frontal_face_detector()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import cv2,matplotlib.pyplot as plt,dlib,imutils\n",
    "from imutils import face_utils\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../input/dlib-68/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "image=plt.imread(\"../input/recognizing-faces-in-the-wild/train/F0002/MID1/P00009_face3.jpg\")\n",
    "# image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "for rect in rects:\n",
    "    pred=predictor(gray,rect)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.scatter(face_utils.shape_to_np(pred)[:,0],face_utils.shape_to_np(pred)[:,1])\n",
    "    \n",
    "# del predictor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import chi2\\n\\ndata = pd.read_csv(cwd + \"/train_data.csv\")\\n\\n#independent columns\\nX = data.iloc[:,0:20]\\n\\n#target column\\ny = data.iloc[:,-1]  \\n\\n#apply SelectKBest class to extract top 10 best features\\nbestfeatures = SelectKBest(score_func=chi2, k=10)\\nfit = bestfeatures.fit(X,y)\\ndfscores = pd.DataFrame(fit.scores_)\\ndfcolumns = pd.DataFrame(X.columns)\\n\\n#concat two dataframes for better visualization \\nfeatureScores = pd.concat([dfcolumns, dfscores],axis=1)\\n\\n#naming the dataframe columns\\nfeatureScores.columns = [\\'Specs\\',\\'Score\\']\\n\\n#print 10 best features\\nprint(featureScores.nlargest(10,\\'Score\\'))\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = pd.read_csv(cwd + \"/train_data.csv\")\n",
    "\n",
    "#independent columns\n",
    "X = data.iloc[:,0:20]\n",
    "\n",
    "#target column\n",
    "y = data.iloc[:,-1]  \n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Specs','Score']\n",
    "\n",
    "#print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.preprocessing import StandardScaler\\n\\nlabel = train.head(1000)\\ndata = train.head(1000)\\ndata.shape\\n\\nstd = StandardScaler().fit_transform(data)\\nstd.shape\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "label = train.head(1000)\n",
    "data = train.head(1000)\n",
    "data.shape\n",
    "\n",
    "std = StandardScaler().fit_transform(data)\n",
    "std.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2, glob, random, math, numpy as np, dlib, itertools\\nfrom sklearn.svm import SVC\\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier\\nfrom sklearn.multiclass import OneVsRestClassifier\\nfrom sklearn import linear_model\\n\\nemotions = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]#, \"Happy\", \"Neutral\", \"Sad\"] #Emotion list\\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\\ndetector = dlib.get_frontal_face_detector()\\npredictor = dlib.shape_predictor(\"/content/drive/MyDrive/Colab Notebooks/shape_predictor_68_face_landmarks.dat\") \\n\\n#clf = SVC(kernel=\\'linear\\', probability=True, tol=1e-3)\\n\\nclf = RandomForestClassifier(min_samples_leaf=3)\\n\\n#clf = linear_model.LogisticRegression(C=1e5)\\n\\n\\n#n_estimators = 10\\n#clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel=\\'linear\\', probability=True, class_weight=\\'balanced\\'), max_samples=1.0 / n_estimators, n_estimators=n_estimators),n_jobs=-1)\\n\\n\\ndef get_files(emotion):\\n    print(\"/content/drive/MyDrive/Colab Notebooks/images/%s/*\" %emotion)\\n    files = glob.glob(r\"/content/drive/MyDrive/Colab Notebooks/images/%s/*\" %emotion)\\n    print(len(files))\\n   \\n    random.shuffle(files)\\n    training = files[:int(len(files)*0.8)] #get first 80% of file list\\n    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\\n   \\n    return training, prediction\\n\\ndef get_landmarks(image):\\n    detections = detector(image, 1)\\n    for k,d in enumerate(detections): #For all detected face instances individually\\n        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\\n        xlist = []\\n        ylist = []\\n        for i in range(1,68): #Store X and Y coordinates in two lists\\n            xlist.append(float(shape.part(i).x))\\n            ylist.append(float(shape.part(i).y))\\n            \\n        xmean = np.mean(xlist) #Get the mean of both axes to determine centre of gravity\\n        ymean = np.mean(ylist)\\n        xcentral = [(x-xmean) for x in xlist] #get distance between each point and the central point in both axes\\n        ycentral = [(y-ymean) for y in ylist]\\n\\n        if xlist[26] == xlist[29]: #If x-coordinates of the set are the same, the angle is 0, catch to prevent \\'divide by 0\\' error in function\\n            anglenose = 0\\n        else:\\n            anglenose = int(math.atan((ylist[26]-ylist[29])/(xlist[26]-xlist[29]))*180/math.pi)\\n\\n        if anglenose < 0:\\n            anglenose += 90\\n        else:\\n            anglenose -= 90\\n\\n        landmarks_vectorised = []\\n        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\\n            landmarks_vectorised.append(x)\\n            landmarks_vectorised.append(y)\\n            meannp = np.asarray((ymean,xmean))\\n            coornp = np.asarray((z,w))\\n            dist = np.linalg.norm(coornp-meannp)\\n            anglerelative = (math.atan((z-ymean)/(w-xmean))*180/math.pi) - anglenose\\n            landmarks_vectorised.append(dist)\\n            landmarks_vectorised.append(anglerelative)\\n\\n    if len(detections) < 1: \\n        landmarks_vectorised = \"error\"\\n    return landmarks_vectorised\\n\\ndef make_sets():\\n    training_data = []\\n    training_labels = []\\n    prediction_data = []\\n    prediction_labels = []\\n    for emotion in emotions:\\n        training, prediction = get_files(emotion)\\n        for item in training:\\n           \\n            image = cv2.imread(item) #open image\\n            if image is not None:\\n              #print(image)\\n              #gray = cv2.cvtColor(np.float32(image), cv2.COLOR_RGB2GRAY)\\n              gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\\n              #gray = rgb2gray(image)\\n\\n              clahe_image = clahe.apply(gray)\\n              landmarks_vectorised = get_gabor(clahe_image)\\n            #if landmarks_vectorised == \"error\":\\n                #pass\\n            #else:\\n              training_data.append(landmarks_vectorised) #append image array to training data list\\n              training_labels.append(emotions.index(emotion))\\n    \\n        for item in prediction:\\n         \\n            image = cv2.imread(item)\\n            if image is not None:\\n              #gray = cv2.cvtColor(np.float32(image), cv2.COLOR_RGB2GRAY)\\n              gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\n              #gray = rgb2gray(image)\\n\\n              clahe_image = clahe.apply(gray)\\n              landmarks_vectorised = get_gabor(clahe_image)\\n            #if landmarks_vectorised == \"error\":\\n                #pass\\n            #else:\\n              prediction_data.append(landmarks_vectorised)\\n              prediction_labels.append(emotions.index(emotion))\\n\\n    return training_data, training_labels, prediction_data, prediction_labels   \\n\\naccur_lin = [] # 10 random set generation\\nfor i in range(0,10):\\n    print(\"Making sets %s\" %i) #Make sets by random sampling 80/20%\\n    training_data, training_labels, prediction_data, prediction_labels = make_sets()\\n\\n    npar_train = np.array(training_data) # numpy array\\n    npar_trainlabs = np.array(training_labels)\\n    \\n    print(\"training model %s\" %i) #train model\\n    clf.fit(npar_train, training_labels)\\n\\n    print(\"getting accuracies %s\" %i)\\n    npar_pred = np.array(prediction_data)\\n    pred_lin = clf.score(npar_pred, prediction_labels)\\n    print (\"Model: \", pred_lin)\\n    accur_lin.append(pred_lin) #Store accuracy in a list\\n\\nprint(\"Mean value accuracy in Model: %.3f\" %np.mean(accur_lin))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2, glob, random, math, numpy as np, dlib, itertools\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "emotions = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]#, \"Happy\", \"Neutral\", \"Sad\"] #Emotion list\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/Colab Notebooks/shape_predictor_68_face_landmarks.dat\") \n",
    "\n",
    "#clf = SVC(kernel='linear', probability=True, tol=1e-3)\n",
    "\n",
    "clf = RandomForestClassifier(min_samples_leaf=3)\n",
    "\n",
    "#clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "\n",
    "#n_estimators = 10\n",
    "#clf = OneVsRestClassifier(BaggingClassifier(SVC(kernel='linear', probability=True, class_weight='balanced'), max_samples=1.0 / n_estimators, n_estimators=n_estimators),n_jobs=-1)\n",
    "\n",
    "\n",
    "def get_files(emotion):\n",
    "    print(\"/content/drive/MyDrive/Colab Notebooks/images/%s/*\" %emotion)\n",
    "    files = glob.glob(r\"/content/drive/MyDrive/Colab Notebooks/images/%s/*\" %emotion)\n",
    "    print(len(files))\n",
    "   \n",
    "    random.shuffle(files)\n",
    "    training = files[:int(len(files)*0.8)] #get first 80% of file list\n",
    "    prediction = files[-int(len(files)*0.2):] #get last 20% of file list\n",
    "   \n",
    "    return training, prediction\n",
    "\n",
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): #For all detected face instances individually\n",
    "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "            \n",
    "        xmean = np.mean(xlist) #Get the mean of both axes to determine centre of gravity\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist] #get distance between each point and the central point in both axes\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "\n",
    "        if xlist[26] == xlist[29]: #If x-coordinates of the set are the same, the angle is 0, catch to prevent 'divide by 0' error in function\n",
    "            anglenose = 0\n",
    "        else:\n",
    "            anglenose = int(math.atan((ylist[26]-ylist[29])/(xlist[26]-xlist[29]))*180/math.pi)\n",
    "\n",
    "        if anglenose < 0:\n",
    "            anglenose += 90\n",
    "        else:\n",
    "            anglenose -= 90\n",
    "\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "            landmarks_vectorised.append(x)\n",
    "            landmarks_vectorised.append(y)\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            anglerelative = (math.atan((z-ymean)/(w-xmean))*180/math.pi) - anglenose\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append(anglerelative)\n",
    "\n",
    "    if len(detections) < 1: \n",
    "        landmarks_vectorised = \"error\"\n",
    "    return landmarks_vectorised\n",
    "\n",
    "def make_sets():\n",
    "    training_data = []\n",
    "    training_labels = []\n",
    "    prediction_data = []\n",
    "    prediction_labels = []\n",
    "    for emotion in emotions:\n",
    "        training, prediction = get_files(emotion)\n",
    "        for item in training:\n",
    "           \n",
    "            image = cv2.imread(item) #open image\n",
    "            if image is not None:\n",
    "              #print(image)\n",
    "              #gray = cv2.cvtColor(np.float32(image), cv2.COLOR_RGB2GRAY)\n",
    "              gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "              #gray = rgb2gray(image)\n",
    "\n",
    "              clahe_image = clahe.apply(gray)\n",
    "              landmarks_vectorised = get_gabor(clahe_image)\n",
    "            #if landmarks_vectorised == \"error\":\n",
    "                #pass\n",
    "            #else:\n",
    "              training_data.append(landmarks_vectorised) #append image array to training data list\n",
    "              training_labels.append(emotions.index(emotion))\n",
    "    \n",
    "        for item in prediction:\n",
    "         \n",
    "            image = cv2.imread(item)\n",
    "            if image is not None:\n",
    "              #gray = cv2.cvtColor(np.float32(image), cv2.COLOR_RGB2GRAY)\n",
    "              gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "              #gray = rgb2gray(image)\n",
    "\n",
    "              clahe_image = clahe.apply(gray)\n",
    "              landmarks_vectorised = get_gabor(clahe_image)\n",
    "            #if landmarks_vectorised == \"error\":\n",
    "                #pass\n",
    "            #else:\n",
    "              prediction_data.append(landmarks_vectorised)\n",
    "              prediction_labels.append(emotions.index(emotion))\n",
    "\n",
    "    return training_data, training_labels, prediction_data, prediction_labels   \n",
    "\n",
    "accur_lin = [] # 10 random set generation\n",
    "for i in range(0,10):\n",
    "    print(\"Making sets %s\" %i) #Make sets by random sampling 80/20%\n",
    "    training_data, training_labels, prediction_data, prediction_labels = make_sets()\n",
    "\n",
    "    npar_train = np.array(training_data) # numpy array\n",
    "    npar_trainlabs = np.array(training_labels)\n",
    "    \n",
    "    print(\"training model %s\" %i) #train model\n",
    "    clf.fit(npar_train, training_labels)\n",
    "\n",
    "    print(\"getting accuracies %s\" %i)\n",
    "    npar_pred = np.array(prediction_data)\n",
    "    pred_lin = clf.score(npar_pred, prediction_labels)\n",
    "    print (\"Model: \", pred_lin)\n",
    "    accur_lin.append(pred_lin) #Store accuracy in a list\n",
    "\n",
    "print(\"Mean value accuracy in Model: %.3f\" %np.mean(accur_lin))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d02cdae7faed44485a20a1dfe89a6c1f0576f684e5ae49a964539fc51d957e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
