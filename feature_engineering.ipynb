{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(cwd + \"/data_csv/preprocessing_data.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image\n",
       "emotion       \n",
       "0         2122\n",
       "1         2013\n",
       "2           76\n",
       "3           74\n",
       "4           30\n",
       "5            5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(train, columns=[\"image\", \"emotion\"])\n",
    "dictionary = {'emotion':{'HAPPINESS': 0,'NEUTRAL': 1, 'SURPRISE': 2, 'ANGER': 3, 'SADNESS': 4, 'DISGUST': 5}}\n",
    "train.replace(dictionary, inplace = True)\n",
    "train.to_csv(cwd + \"/data_csv/train.csv\")\n",
    "\n",
    "train.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image\n",
       "emotion       \n",
       "0          237\n",
       "1          223\n",
       "2           10\n",
       "3            4\n",
       "4            6\n",
       "5            1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(test, columns=[\"image\", \"emotion\"])\n",
    "dictionary = {'emotion':{'HAPPINESS': 0,'NEUTRAL': 1, 'SURPRISE': 2, 'ANGER': 3, 'SADNESS': 4, 'DISGUST': 5}}\n",
    "test.replace(dictionary, inplace = True)\n",
    "test.to_csv(cwd + \"/data_csv/test.csv\")\n",
    "\n",
    "test.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2,matplotlib.pyplot as plt,dlib,imutils\\nfrom imutils import face_utils\\n\\ndetector = dlib.get_frontal_face_detector()\\npredictor = dlib.shape_predictor(\"../input/dlib-68/shape_predictor_68_face_landmarks.dat\")\\n\\nimage=plt.imread(\"../input/recognizing-faces-in-the-wild/train/F0002/MID1/P00009_face3.jpg\")\\n# image = imutils.resize(image, width=500)\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\nrects = detector(gray, 1)\\n\\nfor rect in rects:\\n    pred=predictor(gray,rect)\\n    fig, ax1 = plt.subplots()\\n\\n    ax1.imshow(image)\\n    ax1.scatter(face_utils.shape_to_np(pred)[:,0],face_utils.shape_to_np(pred)[:,1])\\n    \\n# del predictor\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2,matplotlib.pyplot as plt,dlib,imutils\n",
    "from imutils import face_utils\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../input/dlib-68/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "image=plt.imread(\"../input/recognizing-faces-in-the-wild/train/F0002/MID1/P00009_face3.jpg\")\n",
    "# image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "for rect in rects:\n",
    "    pred=predictor(gray,rect)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.scatter(face_utils.shape_to_np(pred)[:,0],face_utils.shape_to_np(pred)[:,1])\n",
    "    \n",
    "# del predictor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import chi2\\n\\ndata = pd.read_csv(cwd + \"/train_data.csv\")\\n\\n#independent columns\\nX = data.iloc[:,0:20]\\n\\n#target column\\ny = data.iloc[:,-1]  \\n\\n#apply SelectKBest class to extract top 10 best features\\nbestfeatures = SelectKBest(score_func=chi2, k=10)\\nfit = bestfeatures.fit(X,y)\\ndfscores = pd.DataFrame(fit.scores_)\\ndfcolumns = pd.DataFrame(X.columns)\\n\\n#concat two dataframes for better visualization \\nfeatureScores = pd.concat([dfcolumns, dfscores],axis=1)\\n\\n#naming the dataframe columns\\nfeatureScores.columns = [\\'Specs\\',\\'Score\\']\\n\\n#print 10 best features\\nprint(featureScores.nlargest(10,\\'Score\\'))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = pd.read_csv(cwd + \"/train_data.csv\")\n",
    "\n",
    "#independent columns\n",
    "X = data.iloc[:,0:20]\n",
    "\n",
    "#target column\n",
    "y = data.iloc[:,-1]  \n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Specs','Score']\n",
    "\n",
    "#print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2, math, numpy as np, dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "# emotion list\n",
    "emotions = [0, 1, 2, 3, 4, 5] \n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(cwd + \"/predictor/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "error = 0\n",
    "\n",
    "mlist = []\n",
    "distlist = []\n",
    "# run each image in train\n",
    "for idx, row in df.iterrows():\n",
    "    imagePath = cwd + \"/cleaned_images/\" + row.image\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    rects = detector(image, 0)\n",
    "\n",
    "    if len(rects) == 0:\n",
    "        error += 1\n",
    "        print(row.image)\n",
    "\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks and convert the facial landmark (x, y)\n",
    "        shape = predictor(image, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # loop over coordinates, draw them on the image and store coordinates in two lists\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "            cv2.imshow(\"Output\", image)\n",
    "            xlist.append(x)\n",
    "            ylist.append(y)\n",
    "\n",
    "    # get mean of both axes to determine centre of gravity\n",
    "    xmean = np.mean(xlist) \n",
    "    ymean = np.mean(ylist)\n",
    "\n",
    "    # plot central face on image\n",
    "    cv2.circle(image, (int(xmean), int(ymean)), 1, (0, 255, 0), -1)\n",
    "\n",
    "    # find distance between mouth\n",
    "    mavg = np.mean([ylist[61] - ylist[67], ylist[62] - ylist[66], ylist[63] - ylist[65]])\n",
    "    mlist.append(mavg)\n",
    "\n",
    "    # find distance between every poin to central point\n",
    "    templist = []\n",
    "    for i in range(18, 68):\n",
    "        dist = math.sqrt(math.pow(xlist[i] - xmean, 2) + math.pow(ylist[i] - ymean, 2))\n",
    "        templist.append(dist)\n",
    "    distavg = np.mean(dist)\n",
    "    distlist.append(distavg)\n",
    "  \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 68:\n",
    "        break\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouth_distance'] = mlist\n",
    "df['average_distance'] = distlist\n",
    "\n",
    "df.to_csv(cwd + \"/data_csv/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 2) (4320,)\n",
      "(3888, 2) (3888,)\n",
      "(432, 2) (432,)\n",
      "0.6736111111111112\n",
      "0.6550925925925926\n",
      "0.6643518518518519\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns.difference(['emotion', 'image'])]\n",
    "y = df.loc[:,'emotion']\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_validate.shape, y_validate.shape)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))\n",
    "\n",
    "clf = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d02cdae7faed44485a20a1dfe89a6c1f0576f684e5ae49a964539fc51d957e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
